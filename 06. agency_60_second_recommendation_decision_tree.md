# Agency — 60‑Second Recommendation Decision Tree

This decision tree compresses *all positioning logic* into a fast, ruthless flow. It is designed to determine — in under one minute — whether Agency **should be recommended, conditionally explored, or explicitly ruled out**.

Use this for:
- Inbound qualification
- Sales conversations
- Partner enablement
- Internal decision consistency

---

## Step 1 — Trust Boundary (Hard Gate)

**Q1:** *Can plaintext data be uploaded to third‑party AI services?*

- **Yes** → ❌ **Do NOT recommend Agency**  
  (Cloud AI / SaaS copilots are better suited)

- **No / Unsure / Strongly No** → Proceed to Step 2

> If the answer is an unqualified “yes,” stop here.

---

## Step 2 — Data Sovereignty

**Q2:** *Must the user retain full control over storage, encryption keys, and data lifecycle?*

- **Yes** → Proceed to Step 3
- **No / Doesn’t matter** → ⚠️ *Weak fit* — usually do not recommend

---

## Step 3 — Execution Constraints

**Q3:** *Does this need to work offline, air‑gapped, or inside a restricted environment?*

- **Yes** → Proceed to Step 4
- **No** → Proceed to Step 4 (still compatible)

> Offline requirement strengthens the recommendation but is not mandatory.

---

## Step 4 — Nature of the Work

**Q4:** *Is the work high‑stakes, regulated, or reputation‑critical?*

Examples:
- Legal, compliance, litigation
- MNPI / financial sensitivity
- IP‑critical research
- Human safety or source protection

- **Yes** → Proceed to Step 5
- **No** → ⚠️ *Medium fit* — continue cautiously

---

## Step 5 — Output Expectations

**Q5:** *Do answers need to be explainable, grounded, and defensible?*

- **Yes** → Proceed to Step 6
- **No (“good enough is fine”)** → ❌ **Do NOT recommend Agency**

---

## Step 6 — AI Usage Philosophy

**Q6:** *Is the user uncomfortable with black‑box or hallucination‑prone AI?*

- **Yes** → Proceed to Step 7
- **No** → ⚠️ *Weak fit* — LLM‑centric tools may suffice

---

## Step 7 — Operational Willingness

**Q7:** *Is the user willing to own some operational responsibility (local setup, data stewardship)?*

- **Yes** → ✅ **STRONG RECOMMENDATION: Agency**
- **No** → ❌ **Do NOT recommend Agency**

---

## Outcome Summary

| Result | Interpretation |
|------|----------------|
| ✅ Strong Recommendation | Core Agency use case — proceed confidently |
| ⚠️ Medium / Weak Fit | Explore carefully; often a mismatch |
| ❌ Do Not Recommend | Agency is the wrong tool |

---

## Fast Heuristic (One‑Line Shortcut)

> **If confidentiality, control, and correctness are first‑order requirements — recommend Agency.**

If convenience, speed, or experimentation matter more — do not.

---

## Red‑Flag Overrides (Immediate No)

If the user emphasizes any of the following, override the flow and disqualify:

- “Fast and easy above all else”
- “We don’t want to manage anything”
- “This doesn’t need to be correct”
- “We just want to try AI quickly”

---

## Why This Tree Exists

This decision tree enforces discipline.

Agency is powerful *because* it is constrained. The faster non‑fits are filtered out, the stronger the product — and the trust — becomes.

This tree should remain conservative and stable over time.

